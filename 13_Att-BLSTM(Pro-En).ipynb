{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README    \n",
    "1. generate a Keras Layer :AttLayer  \n",
    "2. Use csv module to import data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result  \n",
    "1)使用Kmer进行输入 没有效果  \n",
    "    predict 一下 有预测输出，说明训练有效果  \n",
    "    但是 无论是正负样本，预测成负样本的value远远大于正样本的（0.8》》0.2）  \n",
    "    可能是训练时正负样本悬殊引起的  \n",
    "2)正负样本均衡后，acc只有0.61  \n",
    "    将LSTM的num_unit改到50后，收敛速度加快 但是还是在acc=0.60左右  \n",
    "3)考虑扩大样本  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializations\n",
    "from keras import backend as K\n",
    "\n",
    "from collections  import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posdatafile  =  '/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Gen_data/GM12878_pos_all.fa'\n",
    "negdatafile  =   '/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Gen_data/GM12878_neg_all.fa'\n",
    "\n",
    "poslines = open(posdatafile,'r').readlines()\n",
    "neglines = open(negdatafile,'r').readlines()\n",
    "\n",
    "#print poslines[:3]\n",
    "i=0\n",
    "posdata =[]\n",
    "negdata =[]\n",
    "#print len(poslines)\n",
    "for item in range(len(poslines)):\n",
    "    i=i+1\n",
    "    if i%2== 1:\n",
    "        continue\n",
    "    if i%2== 0:\n",
    "        #print item\n",
    "        posdata.append(poslines[item])\n",
    "\n",
    "i=0\n",
    "for item in range(len(neglines)):\n",
    "    i=i+1\n",
    "    if i%2== 1:\n",
    "        continue\n",
    "    if i%2== 0:\n",
    "        negdata.append(neglines[item])\n",
    "    #print negdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Promoter/Enhancer Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyfasta import Fasta\n",
    "genome = Fasta('/home/yinqijin/WorkSpace/DataHub/genome.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获得ｋｍｅｒ的函数\n",
    "d2 = {'a':0, 'A':0, 'g':1, 'G':1, 'c':2, 'C':2, 't':3, 'T':3, 'N':0, 'n':0}\n",
    "def seq_to_kspec(seq):\n",
    "    mat = np.zeros((4096,1))\n",
    "    k = 0\n",
    "    if len(seq)<6:\n",
    "        return mat\n",
    "    for i in range(6):\n",
    "        k = k*4 + d2[seq[i]]\n",
    "    mat[k]+=1  \n",
    "    for i in range(6,len(seq)):\n",
    "        k = k - 4**5*d2[seq[i-6]]\n",
    "        k = k*4 + d2[seq[i]]\n",
    "        mat[k] += 1  \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PESeq=dict()\n",
    "PESeq['Pro-index']=[]\n",
    "PESeq['Pro-Seq']=[]\n",
    "PESeq['Pro-Kmer']=[]\n",
    "PESeq['Ehr-index']=[]\n",
    "PESeq['Ehr-Seq']=[]\n",
    "PESeq['Ehr-Kmer']=[]\n",
    "PESeq['label'] =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range( len( csvdata[csvkeys[0]])):\n",
    "    pro_index = [csvdata['promoter_chrom'][index],csvdata['promoter_start'][index],csvdata['promoter_end'][index]]   \n",
    "    ehr_index = [csvdata['enhancer_chrom'][index],csvdata['enhancer_start'][index] ,csvdata['enhancer_end'][index]]\n",
    "    pro_seq =  genome[csvdata['promoter_chrom'][index]][int(csvdata['promoter_start'][index]) :int(csvdata['promoter_end'][index])].upper()\n",
    "    ehr_seq =  genome[csvdata['enhancer_chrom'][index]] [int(csvdata['enhancer_start'][index]) : int(csvdata['enhancer_end'][index])].upper()    \n",
    "\n",
    "    if len(pro_seq)<6:\n",
    "        print index,'\\tpro_index',pro_index\n",
    "        continue\n",
    "    if len(ehr_seq)<6:\n",
    "        print index,'\\tehr_index',ehr_index\n",
    "        continue\n",
    "    PESeq['Pro-index'].append(pro_index )\n",
    "    PESeq['Pro-Seq'].append(pro_seq)\n",
    "    PESeq['Pro-Kmer'].append( seq_to_kspec(pro_seq))\n",
    "    PESeq['Ehr-index'].append(ehr_index)\n",
    "    PESeq['Ehr-Seq'].append(ehr_seq)\n",
    "    PESeq['Ehr-Kmer'].append(seq_to_kspec(ehr_seq))\n",
    "    PESeq['label'].append(csvdata['label'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print '-'*50\n",
    "for item in PESeq.keys():\n",
    "    print item, np.shape(PESeq[item])\n",
    "print 'pos data' , sum(int( item ) for item in PESeq['label'])\n",
    "print 'neg data',sum(int( 1) if item =='0' else int(0) for item in PESeq['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cut negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_neg_index = [ int(item) for item in PESeq['label']]\n",
    "print pos_neg_index[:50]\n",
    "pos_neg_index = np.array(pos_neg_index )  #很关键\n",
    "\n",
    "neg_index  = np.where(pos_neg_index==0)\n",
    "pos_index  = np.where(pos_neg_index ==1)\n",
    "print neg_index\n",
    "print pos_index\n",
    "bal_pos_neg_index = pos_index + neg_index[:len(pos_index)]\n",
    "print bal_pos_neg_index[:50]\n",
    "print bal_pos_neg_index[-50:]\n",
    "print len(bal_pos_neg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'lengthest Enhancer',len(max(PESeq['Ehr-Seq'],key= lambda x:len(x)))\n",
    "print  'lengthest Promoter',len(max(PESeq['Pro-Seq'],key= lambda x:len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Get X,Y with no  limited\n",
    "X=[]\n",
    "Y=[]\n",
    "for index in range( len( PESeq['label'])):\n",
    "    Y.append(PESeq['label'][index])\n",
    "    X.append(np.append(PESeq['Pro-Kmer'][index],PESeq['Ehr-Kmer'][index],axis=1))\n",
    "print np.shape(X)\n",
    "print np.shape(Y)\n",
    "X = np.array(X)\n",
    "Y  = np.array(Y)\n",
    "\n",
    "index = range(len(PESeq['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get X,Y with   limite  making positive and negative samples 's numbers is the same\n",
    "X=[]\n",
    "Y=[]\n",
    "for index in range( 4220):\n",
    "    Y.append(PESeq['label'][index])\n",
    "    X.append(np.append(PESeq['Pro-Kmer'][index],PESeq['Ehr-Kmer'][index],axis=1))\n",
    "print np.shape(X)\n",
    "print np.shape(Y)\n",
    "X = np.array(X)\n",
    "Y  = np.array(Y)\n",
    "\n",
    "\n",
    "index = range(4220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "VALIDATION_SPLIT =0.2\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "np.random.shuffle(index)\n",
    "nb_validation_samples = int(VALIDATION_SPLIT*len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train = X[index[: - nb_validation_samples]]\n",
    "y_train = Y[index[:-nb_validation_samples]]\n",
    "x_val = X[index[-nb_validation_samples:]]\n",
    "y_val =Y[index[-nb_validation_samples:]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train) #one-hot 编码labels\n",
    "y_val = to_categorical(np.asarray(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'x_train_shape:',np.shape(x_train)\n",
    "print 'y_train_shape:',np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#使验证集正负样本数量相等\n",
    "print np.shape(y_val)\n",
    "\n",
    "print 'valid负正样本比例' sum(y_val)\n",
    "\n",
    "\n",
    "count = defaultdict()\n",
    "count['0']=[]\n",
    "count['1']=[]\n",
    "for i in range(8847):\n",
    "    if y_val[i][0]==1:\n",
    "        count['0'].append(i)\n",
    "    else:\n",
    "        count['1'].append(i)\n",
    "print len(count['0']),len(count['1'])\n",
    "\n",
    "\n",
    " index_my = count['0'][:401]+count['1']\n",
    "\n",
    "x_val_my = x_val[index_my,:,:]\n",
    "y_val_my  =y_val[index_my,:]\n",
    "\n",
    "print 'x_val_shape:',np.shape(x_val_my)\n",
    "print 'y_val_shape:',np.shape(y_val_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_val_my\n",
    "print x_val_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hickle as hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hkl.dump(x_val,'./Gen_data/10_Att_BLSTM_x_val.hkl')\n",
    "hkl.dump(y_val,'./Gen_data/10_Att_BLSTM_y_val.hkl')\n",
    "hkl.dump(x_train,'./Gen_data/10_Att_BLSTM_x_train.hkl')\n",
    "hkl.dump(y_train,'./Gen_data/10_Att_BLSTM_y_train.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "x_val = hkl.load('./Gen_data/10_Att_BLSTM_x_val.hkl')\n",
    "y_val = hkl.load('./Gen_data/10_Att_BLSTM_y_val.hkl')\n",
    "x_train = hkl.load('./Gen_data/10_Att_BLSTM_x_train.hkl')\n",
    "y_train = hkl.load('./Gen_data/10_Att_BLSTM_y_train.hkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这一个是负样本均衡过的\n",
    "import hickle as hkl\n",
    "x_val = hkl.load('./Gen_data/13_x_val.hkl')\n",
    "y_val = hkl.load('./Gen_data/13_y_val.hkl')\n",
    "x_train = hkl.load('./Gen_data/13_x_train.hkl')\n",
    "y_train = hkl.load('./Gen_data/13_y_train.hkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializations\n",
    "from keras import backend as K\n",
    "\n",
    "from collections  import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = initializations.get('normal')\n",
    "        #self.input_spec = [InputSpec(ndim=3)]\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        #self.W = self.init((input_shape[-1],1))\n",
    "        self.W = self.init((input_shape[-1],))\n",
    "        #self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "\n",
    "\n",
    "        M = K.tanh(x)\n",
    "        alpha = K.dot(M,self.W)#.dimshuffle(0,2,1)\n",
    "\n",
    "        ai = K.exp(alpha)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return K.tanh(weighted_input.sum(axis=1))\n",
    "        '''\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "\n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "\n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "        '''\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense,Input,Activation\n",
    "from keras.layers import Embedding, LSTM, Bidirectional,GRU,InputLayer\n",
    "from keras.models import Model,Sequential\n",
    "from  keras.regularizers import ActivityRegularizer\n",
    "from keras.layers.core import Dropout,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmer_input = Input(shape=(4096,2), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_lstm =Bidirectional(LSTM(5,return_sequences=True))(kmer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_lstm_drop = Dropout(0.3)(l_lstm)\n",
    "l_att = AttLayer()(l_lstm_drop)\n",
    "l_flatten = Flatten()(l_lstm_drop)\n",
    "l_att_drop = Dropout(0.5)(l_flatten)\n",
    "l_dense = Dense(32)(l_att_drop)\n",
    "preds = Dense(len( y_train[0]), activation='softmax',activity_regularizer= ActivityRegularizer(l2=0.005))(l_dense)\n",
    "model  = Model (kmer_input,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - attention LSTM network\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 4096, 2)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 4096, 10)      320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096, 10)      0           bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 40960)         0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 40960)         0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            1310752     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             66          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,311,138\n",
      "Trainable params: 1,311,138\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - attention LSTM network\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3376 samples, validate on 843 samples\n",
      "Epoch 1/20\n",
      " 600/3376 [====>.........................] - ETA: 231s - loss: 0.9116 - acc: 0.5233"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), nb_epoch=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pro = model.predict_on_batch(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save&Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./Gen_data/10_Att-BLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./Gen_data/10_Att-BLSTM.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
