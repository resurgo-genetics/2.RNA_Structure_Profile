{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4218, 800)\n",
      "(800,)\n",
      "(4218, 800)\n",
      "(4096, 100)\n",
      "(4096, 100)\n",
      "(800,) [ 0.  1.]\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 800)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 800, 100)      409600                                       \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 800)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 800, 100)      409600                                       \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 4)             3248        merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 32)            160         bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             66          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 822,674\n",
      "Trainable params: 822,674\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 3585 samples, validate on 633 samples\n",
      "Epoch 1/20\n",
      "3585/3585 [==============================] - 77s - loss: 0.5677 - acc: 0.5741 - val_loss: 0.6220 - val_acc: 0.0016\n",
      "Epoch 2/20\n",
      "1024/3585 [=======>......................] - ETA: 54s - loss: 0.5666 - acc: 0.5869"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "input_file = open('./Gen_data/14_Network_input.pkl','r')\n",
    "pro_input = pkl.load(input_file)\n",
    "ehr_input = pkl.load(input_file)\n",
    "Y=pkl.load(input_file)\n",
    "input_file.close()\n",
    "\n",
    "print np.shape(pro_input)\n",
    "print np.shape(pro_input[0])\n",
    "print np.shape(ehr_input)\n",
    "\n",
    "\n",
    "input_file = open('./Gen_data/14_embedding_matrix.pkl','r')\n",
    "pro_embedding_matrix = pkl.load(input_file)\n",
    "ehr_embedding_matrix = pkl.load(input_file)\n",
    "input_file.close()\n",
    "\n",
    "print np.shape(pro_embedding_matrix)\n",
    "print np.shape(ehr_embedding_matrix)\n",
    "# 切分训练集\n",
    "\n",
    "from numpy.random import shuffle\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "SPLIT_point = int(0.85*len(Y))\n",
    "seq_index = range(len(Y))\n",
    "shuffle(seq_index)\n",
    "\n",
    "Y = to_categorical(Y)\n",
    "x_train ,y_train =pro_input[:SPLIT_point], Y[:SPLIT_point]\n",
    "x_valid ,y_valid = pro_input[SPLIT_point:], Y[SPLIT_point:]\n",
    "\n",
    "x_train_ehr ,x_valid_ehr =ehr_input[:SPLIT_point], ehr_input[SPLIT_point:]\n",
    "\n",
    "print np.shape(x_train[0]),y_train[0]\n",
    "\n",
    "# Network\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Embedding,InputLayer\n",
    "from keras.layers import Dense,Input,Activation\n",
    "from keras.layers import Embedding, LSTM, Bidirectional,GRU,InputLayer\n",
    "from keras.models import Model,Sequential\n",
    "from  keras.regularizers import ActivityRegularizer\n",
    "from keras.layers.core import Dropout,Flatten,Merge\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# temp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "EMBEDDING_DIM =100\n",
    "MAX_SEQUENCE_LENGTH = 800  \n",
    "nb_words =4096   #字典的len(keys())\n",
    "\n",
    "# other network\n",
    "\n",
    "embedding_layer = Embedding(nb_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[pro_embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "ehr_embedding_layer = Embedding(nb_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[pro_embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "left = Sequential()\n",
    "left.add( InputLayer(input_shape=(MAX_SEQUENCE_LENGTH,),input_dtype='int32'))\n",
    "left.add(embedding_layer)\n",
    "\n",
    "right = Sequential()\n",
    "right.add( InputLayer(input_shape=(MAX_SEQUENCE_LENGTH,),input_dtype='int32'))\n",
    "right.add(ehr_embedding_layer)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='concat'))\n",
    "model.add(Bidirectional(LSTM(2,return_sequences=False)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(2, activation='softmax',activity_regularizer= ActivityRegularizer(l2=0.005)))\n",
    "model.compile(loss='mse', optimizer='rmsprop',metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "model.fit([x_train, x_train_ehr], y_train, batch_size=128, nb_epoch=20, validation_data=([x_valid, x_valid_ehr], y_valid))\n",
    "\n",
    "print 'finish!'\n",
    "\n",
    "\n",
    "\n",
    "pro = model.predict_on_batch([x_valid,x_valid_ehr])\n",
    "\n",
    "y_pred = [ 1 if item1>item0 else 0 for item0,item1 in pro]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "acc = metrics.accuracy_score(y_valid[:,1],y_pred)\n",
    "print acc\n",
    "a\n",
    "auc = metrics.roc_auc_score(y_valid[:,1],pro[:,1])\n",
    "print auc\n",
    "\n",
    "f1_score = metrics.f1_score(y_valid[:,1],y_pred)\n",
    "print f1_score\n",
    "\n",
    "\n",
    "\n",
    "model.save_weights('./Gen_data/14_Att-BLSTM_model.h5')\n",
    "print 'save model finished!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
