{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hickle  as hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 =hkl.load('./Gen_data/CROSS_Net_input.hkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate LSTM NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layersgne.layers import InputLayer\n",
    "from lasagne.layers import LSTMLayer\n",
    "from lasagne.layers import ReshapeLlasagne\n",
    "from lasagne.layers import DenseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.updates import adam\n",
    "from lasagne.objectives import squared_error\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inititalization gate\n",
    "gate_parameters = lasagne.layers.recurrent.Gate(\n",
    "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
    "    b=lasagne.init.Constant(0.))\n",
    "\n",
    "cell_parameters = lasagne.layers.recurrent.Gate(\n",
    "    W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
    "    # Setting W_cell to None denotes that no cell connection will be used.\n",
    "    W_cell=None, b=lasagne.init.Constant(0.),\n",
    "    # By convention, the cell nonlinearity is tanh in an LSTM.\n",
    "    nonlinearity=lasagne.nonlinearities.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minibatch,cutdown_len,num_units, = 13, 13, 5\n",
    "N_HIDDEN=10\n",
    "l_in = InputLayer(shape=(128,minibatch,1))  \n",
    "layer_mask = InputLayer(shape=(128,minibatch))\n",
    "layer2 = LSTMLayer(layer1,N_HIDDEN,mask_input=layer_mask,ingate=gate_parameters,\n",
    "                   cell=cell_parameters,outgate=gate_parameters,learn_init=True,grad_clipping=100.)\n",
    "layer2_back = LSTMLayer(layer1,N_HIDDEN,mask_input=layer_mask,ingate=gate_parameters,  \n",
    "                   cell=cell_parameters,outgate=gate_parameters,learn_init=True,grad_clipping=100.,backwards=True)\n",
    "# We'll combine the forward and backward layer output by summing.\n",
    "# Merge layers take in lists of layers to merge as input.\n",
    "l_sum = lasagne.layers.ElemwiseSumLayer([layer2, layer2_back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, retrieve symbolic variables for the input shape\n",
    "n_batch, n_time_steps, n_features = l_in.input_var.shape\n",
    "# Now, squash the n_batch and n_time_steps dimensions\n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_sum, (-1, N_HIDDEN))\n",
    "# Now, we can apply feed-forward layers as usual.\n",
    "# We want the network to predict a single value, the sum, so we'll use a single unit.\n",
    "l_dense1 = lasagne.layers.DenseLayer(\n",
    "    l_reshape, num_units=5, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "network = lasagne.layers.DenseLayer(\n",
    "    l_dense1, num_units=1, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "# Now, the shape will be n_batch*n_timesteps, 1.  We can then reshape to\n",
    "# n_batch, n_timesteps to get a single value for each timstep from each sequence\n",
    "l_out = lasagne.layers.ReshapeLayer(network, (n_batch, n_time_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MissingInputError",
     "evalue": "An input of the graph, used to compute InplaceDimShuffle{1,0,2}(input), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\n\nBacktrace when the variable is created:\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-318-2a59dc4e76f8>\", line 2, in <module>\n    layer1 = InputLayer(shape=(128,minibatch,1))\n  File \"/home/yinqijin/anaconda2/bin/src/lasagne/lasagne/layers/input.py\", line 63, in __init__\n    input_var = input_var_type(var_name)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingInputError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-d15cb32306df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Theano functions for training and computing cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m train = theano.function(\n\u001b[0;32m---> 19\u001b[0;31m     [l_in.input_var, target_values, layer_mask.input_var],cost, updates=updates)\n\u001b[0m\u001b[1;32m     20\u001b[0m compute_cost = theano.function(\n\u001b[1;32m     21\u001b[0m     [l_in.input_var, target_values, layer_mask.input_var], cost)\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m             defaults)\n\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0;31m# OUTPUT VARIABLES)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             fgraph, additional_outputs = std_fgraph(inputs, outputs,\n\u001b[0;32m-> 1437\u001b[0;31m                                                     accept_inplace)\n\u001b[0m\u001b[1;32m   1438\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mstd_fgraph\u001b[0;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     fgraph = gof.fg.FunctionGraph(orig_inputs, orig_outputs,\n\u001b[0;32m--> 176\u001b[0;31m                                   update_mapping=update_mapping)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, features, clone, update_mapping)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import_r__\u001b[0;34m(self, variable, reason)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# Imports the owners of the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         elif (variable.owner is None and\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/gof/fg.pyc\u001b[0m in \u001b[0;36m__import__\u001b[0;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             \u001b[0;34m\"for more information on this error.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                             % str(node)),\n\u001b[0;32m--> 396\u001b[0;31m                             variable=r)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingInputError\u001b[0m: An input of the graph, used to compute InplaceDimShuffle{1,0,2}(input), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\n\nBacktrace when the variable is created:\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-318-2a59dc4e76f8>\", line 2, in <module>\n    layer1 = InputLayer(shape=(128,minibatch,1))\n  File \"/home/yinqijin/anaconda2/bin/src/lasagne/lasagne/layers/input.py\", line 63, in __init__\n    input_var = input_var_type(var_name)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Symbolic variable for the target network output.\n",
    "# It will be of shape n_batch, because there's only 1 target value per sequence.\n",
    "target_values = theano.tensor.vector('target_output')\n",
    "\n",
    "# lasagne.layers.get_output produces an expression for the output of the net\n",
    "network_output = lasagne.layers.get_output(l_out)\n",
    "# The value we care about is the final value produced for each sequence\n",
    "# so we simply slice it out.\n",
    "predicted_values = network_output[:, -1]\n",
    "# Our cost will be mean-squared error\n",
    "cost =  theano.tensor.mean((predicted_values - target_values)**2)\n",
    "# Retrieve all parameters from the network\n",
    "all_params = lasagne.layers.get_all_params(l_out)\n",
    "# Compute adam updates for training\n",
    "updates = lasagne.updates.adam(cost, all_params)\n",
    "# Theano functions for training and computing cost\n",
    "train = theano.function(\n",
    "    [l_in.input_var, target_values, layer_mask.input_var],cost, updates=updates)\n",
    "compute_cost = theano.function( [l_in.input_var, target_values, layer_mask.input_var], cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ones' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-336-a2c98d84a7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ones' is not defined"
     ]
    }
   ],
   "source": [
    "# We'll train the network with 10 epochs of 100 minibatches each\n",
    "NUM_EPOCHS = 100\n",
    "EPOCH_SIZE = 10\n",
    "m = ones(minibatch,1)\n",
    "print m\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for _ in range(EPOCH_SIZE):\n",
    "        train(X_train, y_train, m)\n",
    "    #if epoch%10==0:\n",
    "    cost_val = compute_cost(X_test, y_test, m)\n",
    "    print(\"Epoch {} validation cost = {}\".format(epoch + 1, cost_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "lr = theano.shared(np.float32(1e-4))\n",
    "\n",
    "net = NeuralNet(\n",
    "            network,\n",
    "            max_epochs=50,\n",
    "            update=adam,\n",
    "            update_learning_rate=lr,\n",
    "            train_split=TrainSplit(eval_size=0.1),\n",
    "                regression = True,\n",
    "            objective_loss_function = squared_error,\n",
    "            #on_epoch_finished=[\n",
    "            #    AdjustVariable(lr, target=1e-8, half_life=20)],\n",
    "            verbose=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test  \n",
    "网络输入使用one-hot编码，不能运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutdown_len,num_units = 13, 4\n",
    "layer1 = InputLayer(shape=(None,cutdown_len,4))  #输入是序列的one-hot编码\n",
    "layer2 = LSTMLayer(layer1,num_units= num_units)\n",
    "layer3 = ReshapeLayer(layer2,(-1,num_units))\n",
    "layer4 = DenseLayer(layer3,num_units=5 ,nonlinearity=tanh)\n",
    "network = DenseLayer(layer4,num_units=1,nonlinearity=tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cutdown_len = 13\n",
    "layer1 = InputLayer(shape=(None,cutdown_len,4))\n",
    "layer2 = DenseLayer(layer1, num_units=20 ,nonlinearity=tanh)\n",
    "network = DenseLayer(layer2,num_units=1,nonlinearity=tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = theano.shared(np.float32(1e-4))\n",
    "\n",
    "net = NeuralNet(\n",
    "            network,\n",
    "            max_epochs=50,\n",
    "            update=adam,\n",
    "            update_learning_rate=lr,\n",
    "            train_split=TrainSplit(eval_size=0.1),\n",
    "                regression = True,\n",
    "            objective_loss_function = squared_error,\n",
    "            #on_epoch_finished=[\n",
    "            #    AdjustVariable(lr, target=1e-8, half_life=20)],\n",
    "            verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data2['mat']\n",
    "Y = data2['score']\n",
    "\n",
    "Y_ = [ item[(len(item)-1)/2] for item in Y]\n",
    "Y_ = np.array(Y_)\n",
    "\n",
    "X_ = np.zeros((len(X),4,cutdown_len))\n",
    "X_[:,:,:] = X[:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "rs = ShuffleSplit(len(Y_), n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_idx, test_idx in rs:\n",
    "    X_train = X_[train_idx,:]\n",
    "    y_train = Y_[train_idx]\n",
    "    X_test = X_[test_idx,:]\n",
    "    y_test = Y_[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.]]\n",
      "\n",
      " [[ 1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  1.]\n",
      "  [ 0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]]\n",
      "[ 0.021  0.301]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "print X_train[:2]\n",
    "print y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 251 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #    name  size\n",
      "---  ------  ------\n",
      "  0          13x4\n",
      "  1          13x5\n",
      "  2          5\n",
      "  3          5\n",
      "  4          1\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (512,13)x(4,20)->(512,20)\nApply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuJoin.0)\nToposort index: 91\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(512, 13), (4, 20)]\nInputs strides: [(13, 1), (20, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-e7c13d3cbd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_iterator_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 train_outputs.append(\n\u001b[0;32m--> 737\u001b[0;31m                     self.apply_batch_func(self.train_iter_, Xb, yb))\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0mbatch_train_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mapply_batch_func\u001b[0;34m(func, Xb, yb)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    887\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch in args to gemm (512,13)x(4,20)->(512,20)\nApply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuJoin.0)\nToposort index: 91\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(512, 13), (4, 20)]\nInputs strides: [(13, 1), (20, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp =[]\n",
    "for string in data2['seq']:\n",
    "    temp.append([ item for item in string])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#j将碱基序列转化为数字序列\n",
    "#d = {'a':1, 'A':1, 'g':2, 'G':2, 'c':3, 'C':3, 't':4, 'T':4, 'N':5, 'n':5}\n",
    "d = {'a':1.1, 'A':1.1, 'g':3.5, 'G':3.5, 'c':5.6, 'C':5.6, 't':7.9, 'T':7.9, 'N':11, 'n':11}\n",
    "func = lambda x:d[x]\n",
    "\n",
    "X_pd = pd.DataFrame(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_=X_pd.applymap(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X_.values[:,:]\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data2['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_ = [ item[(len(item)-1)/2] for item in Y]\n",
    "Y_ = np.array(Y_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.5  3.5  3.5  1.1  3.5  5.6  5.6  5.6  1.1  3.5  1.1  1.1  3.5]\n",
      " [ 3.5  3.5  1.1  3.5  5.6  5.6  5.6  1.1  3.5  1.1  1.1  3.5  3.5]]\n",
      "[ 0.015  0.002]\n"
     ]
    }
   ],
   "source": [
    "print X[:2]\n",
    "print Y_[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "rs = ShuffleSplit(len(Y_), n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_idx, test_idx in rs:\n",
    "    X_train = X[train_idx,:]\n",
    "    y_train = Y_[train_idx]\n",
    "    X_test = X[test_idx,:]\n",
    "    y_test = Y_[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10000002  1.10000002  1.10000002  3.5         1.10000002  5.5999999\n",
      "   7.9000001   5.5999999   1.10000002  5.5999999   7.9000001   3.5\n",
      "   7.9000001 ]\n",
      " [ 3.5         3.5         5.5999999   5.5999999   1.10000002  5.5999999\n",
      "   1.10000002  5.5999999   7.9000001   1.10000002  1.10000002  5.5999999\n",
      "   7.9000001 ]]\n",
      "[ 0.31900001 -0.59399998]\n"
     ]
    }
   ],
   "source": [
    "print X_train[:2]\n",
    "print y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 571 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #    name  size\n",
      "---  ------  ------\n",
      "  0          13x1\n",
      "  1          13x10\n",
      "  2          10\n",
      "  3          5\n",
      "  4          1\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.py:639\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-128-5214563a6458>\", line 2, in <module>\n    layer1 = InputLayer(shape=(None,cutdown_len,1))\n  File \"/home/yinqijin/anaconda2/bin/src/lasagne/lasagne/layers/input.py\", line 63, in __init__\n    input_var = input_var_type(var_name)\nWrong number of dimensions: expected 3, got 2 with shape (128, 13).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-e7c13d3cbd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_iterator_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 train_outputs.append(\n\u001b[0;32m--> 737\u001b[0;31m                     self.apply_batch_func(self.train_iter_, Xb, yb))\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0mbatch_train_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mapply_batch_func\u001b[0;34m(func, Xb, yb)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    787\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yinqijin/Theano/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    176\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[1;32m    177\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[0;32m--> 178\u001b[0;31m                                                         data.shape))\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Bad input argument to theano function with name \"/home/yinqijin/.local/lib/python2.7/site-packages/nolearn/lasagne/base.py:639\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yinqijin/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-128-5214563a6458>\", line 2, in <module>\n    layer1 = InputLayer(shape=(None,cutdown_len,1))\n  File \"/home/yinqijin/anaconda2/bin/src/lasagne/lasagne/layers/input.py\", line 63, in __init__\n    input_var = input_var_type(var_name)\nWrong number of dimensions: expected 3, got 2 with shape (128, 13)."
     ]
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2 \n",
    "直接用碱基序列做LSTM  \n",
    "\n",
    "结果: \n",
    "    １．不准确\n",
    "问题: 　\n",
    "    1. 输入是序列，输出是概率，不是同一类，可以推出来么？\n",
    "    ２. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lstm import LstmParam, LstmNetwork\n",
    "\n",
    "class ToyLossLayer:\n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def loss(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] = 2 * (pred[0] - label)\n",
    "        return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "losss =[]\n",
    "def example_0():\n",
    "    # learns to repeat simple sequence from random inputs\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # parameters for input data dimension and lstm cell count \n",
    "    mem_cell_ct = 100\n",
    "    x_dim =  13\n",
    "    concat_len = x_dim + mem_cell_ct\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim) \n",
    "    lstm_net = LstmNetwork(lstm_param)\n",
    "    y_list = y_train[:1000]\n",
    "    input_val_arr = X_train[:1000,:]\n",
    "\n",
    "    for cur_iter in range(100):\n",
    "        print \"cur iter: \", cur_iter\n",
    "        for ind in range(len(y_list)):\n",
    "            lstm_net.x_list_add(input_val_arr[ind])\n",
    "            #print \"y_pred[%d] : %f\" % (ind, lstm_net.lstm_node_list[ind].state.h[0])\n",
    "\n",
    "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "        #print \"loss: \", loss\n",
    "        losss.append(loss)\n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        lstm_net.x_list_clear()\n",
    "    print 'finish'\n",
    "    print losss\n",
    "    for ind in range(len(y_list)):\n",
    "        lstm_net.x_list_add(input_val_arr[ind])\n",
    "        print \"y_pred[%d] : %f\\t\\t%f\" % (ind, lstm_net.lstm_node_list[ind].state.h[0],y_train[ind])\n",
    "\n",
    "    loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "    losss.append(loss)\n",
    "    lstm_param.apply_diff(lr=0.1)\n",
    "    lstm_net.x_list_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 直接用碱基序列\n",
    "def example_0():\n",
    "    # learns to repeat simple sequence from random inputs\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # parameters for input data dimension and lstm cell count \n",
    "    mem_cell_ct = 1000\n",
    "    x_dim = 13\n",
    "    concat_len = x_dim + mem_cell_ct\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim) \n",
    "    lstm_net = LstmNetwork(lstm_param)\n",
    "    y_list =  y_train[:10]\n",
    "    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n",
    "    input_val_arr =[ temp  for temp in X_train[:10,:]]\n",
    "    print np.shape(input_val_arr)\n",
    "    print input_val_arr[:3]\n",
    "    \n",
    "    for cur_iter in range(100):\n",
    "        if cur_iter%5== 0:\n",
    "            print \"cur iter: \", cur_iter\n",
    "        for ind in range(len(y_list)):\n",
    "            lstm_net.x_list_add(input_val_arr[ind])\n",
    "            if (ind%5==0)&(cur_iter%5==0):\n",
    "               print \"y_pred[%d] : %f\\t%f\\n\" % (ind, lstm_net.lstm_node_list[ind].state.h[0],y_train[ind])\n",
    "\n",
    "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "        if cur_iter%5==0:\n",
    "            print \"loss: \", loss\n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        lstm_net.x_list_clear()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    print \"cur iter: \", '1001'\n",
    "    for ind in range(len(y_list)):\n",
    "        lstm_net.x_list_add(input_val_arr[ind])\n",
    "        print \"y_pred[%d] : %f\\t%f\\n\" % (ind, lstm_net.lstm_node_list[ind].state.h[0],y_train[ind])\n",
    "\n",
    "    loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "    print \"loss: \", loss\n",
    "    lstm_param.apply_diff(lr=0.1)\n",
    "    lstm_net.x_list_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 13)\n",
      "[array([ 1.10000002,  1.10000002,  1.10000002,  3.5       ,  1.10000002,\n",
      "        5.5999999 ,  7.9000001 ,  5.5999999 ,  1.10000002,  5.5999999 ,\n",
      "        7.9000001 ,  3.5       ,  7.9000001 ], dtype=float32), array([ 3.5       ,  3.5       ,  5.5999999 ,  5.5999999 ,  1.10000002,\n",
      "        5.5999999 ,  1.10000002,  5.5999999 ,  7.9000001 ,  1.10000002,\n",
      "        1.10000002,  5.5999999 ,  7.9000001 ], dtype=float32), array([ 1.10000002,  1.10000002,  1.10000002,  5.5999999 ,  3.5       ,\n",
      "        7.9000001 ,  1.10000002,  5.5999999 ,  7.9000001 ,  3.5       ,\n",
      "        7.9000001 ,  7.9000001 ,  7.9000001 ], dtype=float32)]\n",
      "cur iter:  0\n",
      "y_pred[0] : 0.479539\t0.319000\n",
      "\n",
      "y_pred[5] : 0.120963\t0.000000\n",
      "\n",
      "loss:  7.68951441284\n",
      "cur iter:  5\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  10\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  15\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  20\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  25\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  30\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  35\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  40\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  45\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  50\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  55\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  60\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  65\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  70\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  75\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  80\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  85\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  90\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n",
      "cur iter:  95\n",
      "y_pred[0] : -0.000000\t0.319000\n",
      "\n",
      "y_pred[5] : -0.000000\t0.000000\n",
      "\n",
      "loss:  0.779439977122\n"
     ]
    }
   ],
   "source": [
    "example_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_0():\n",
    "    # learns to repeat simple sequence from random inputs\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # parameters for input data dimension and lstm cell count \n",
    "    mem_cell_ct = 1000\n",
    "    x_dim = 50\n",
    "    concat_len = x_dim + mem_cell_ct\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim) \n",
    "    lstm_net = LstmNetwork(lstm_param)\n",
    "    y_list = [-0.5,0.2,0.1, -0.5]\n",
    "    input_val_arr = [ np.floor(np.random.random(x_dim)) for _ in y_list]\n",
    "\n",
    "    for cur_iter in range(500):\n",
    "        print \"cur iter: \", cur_iter\n",
    "        for ind in range(len(y_list)):\n",
    "            lstm_net.x_list_add(input_val_arr[ind])\n",
    "            print \"y_pred[%d] : %f\" % (ind, lstm_net.lstm_node_list[ind].state.h[0])\n",
    "\n",
    "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "        print \"loss: \", loss\n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        lstm_net.x_list_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
