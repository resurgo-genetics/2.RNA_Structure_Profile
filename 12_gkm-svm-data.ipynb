{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from pyfasta import Fasta\n",
    "genome = Fasta('/home/yinqijin/WorkSpace/DataHub/genome.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HeLa-S3\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/NHEK\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/IMR90\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/K562\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/combined\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HUVEC\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "GM12878is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HeLa-S3\n",
      "HeLa-S3is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/NHEK\n",
      "NHEKis processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/IMR90\n",
      "IMR90is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/K562\n",
      "K562is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/combined\n",
      "combinedis processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HUVEC\n",
      "HUVECis processed!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "baseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            breakbaseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "\n",
    "#method2. 读取部分并计算新键\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            break\n",
    "    \n",
    "    #新建初始化变量\n",
    "    #method1.读取全部内容\n",
    "    #----------------------------\n",
    "    #PESeq = {}\n",
    "    #for name in excel_name:\n",
    "    #    PESeq[name] = []\n",
    "    #---------------------------\n",
    "    \n",
    "    Pos_num =0\n",
    "    Neg_num =0\n",
    "        #-------------------------------\n",
    "    PESeq={}\n",
    "    PESeq['posdata']=[]\n",
    "    PESeq['negdata']=[]\n",
    "    #PESeq['label'] =[]\n",
    "    #--------------------------------\n",
    "    \n",
    "    #读取CSV内容并结构化\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Add values of every keys to the csvdata for every row\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) <200 :\n",
    "                if     row['label']==0:\n",
    "                    print row\n",
    "                    continue\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) >40950 :\n",
    "    \n",
    "                print row\n",
    "                continue\n",
    "            if abs(int(row['promoter_start'] )-int( row['promoter_end'])) >40950 :\n",
    "                print row\n",
    "                continue                    \n",
    "            #正负样本均衡\n",
    "            if  row['label']==str(1):\n",
    "                Pos_num+=1\n",
    "            elif  row['label']==str(0) :\n",
    "                Neg_num+=1  \n",
    "            if Neg_num>Pos_num:\n",
    "                break\n",
    "            #method1.读取全部内容   \n",
    "            #---------------------------\n",
    "            #for item in csvkeys:\n",
    "            #    csvdata[item].append(row[item])\n",
    "            #------------------------------\n",
    "            #method2. 读取部分并计算新键\n",
    "            #-------------------------------\n",
    "            pro_index = row['promoter_chrom']+ ':' +row['promoter_start']+ '-'+ row['promoter_end']\n",
    "            ehr_index = row['enhancer_chrom'] +':'+ row['enhancer_start'] +'-'+row['enhancer_end']\n",
    "            pro_seq =  genome[row['promoter_chrom']][int(row['promoter_start']) :int(row['promoter_end'])] .upper()   \n",
    "            pro_seq = str(pro_seq)\n",
    "            ehr_seq =  genome[row['enhancer_chrom'] ][int(row['enhancer_start']) : int(row['enhancer_end'])].upper()    \n",
    "            ehr_seq = str(ehr_seq)\n",
    "            \n",
    "            record = SeqRecord(Seq(pro_seq+ehr_seq),id = pro_index, description=\"\")\n",
    "            if row['label']==str(0):\n",
    "                PESeq['negdata'].append(record )\n",
    "            if row['label']== str(1):\n",
    "                PESeq['posdata'].append(record)\n",
    "                \n",
    "                \n",
    "            #f row['label']==str(0):\n",
    "            #    PESeq['negdata'].append('>'+pro_index +'\\n' ) #+'-' +ehr_index\n",
    "            #    PESeq['negdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            #if row['label']== str(1):\n",
    "            #    PESeq['posdata'].append('>'+pro_index +'\\n' )#+'-' +ehr_index\n",
    "             #   PESeq['posdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            #PESeq['label'].append(row['label'])\n",
    "            #print  [ pro_index '  -  ' ehr_index ]\n",
    "            #print [pro_seq ehr_seq]\n",
    "            #--------------------------------\n",
    "    #with open('./Gen_data/'+sub_dir+'_pos.fa','w') as f:\n",
    "    #    f.writelines(PESeq['posdata'])\n",
    "        \n",
    "    #with  open('./Gen_data/'+sub_dir+'_neg.fa','w') as f:\n",
    "    #    f.writelines(PESeq['negdata'])\n",
    "    SeqIO.write(PESeq['negdata'], \"./Gen_data/\"+sub_dir+\"_neg.fa\",\"fasta\")\n",
    "    SeqIO.write(PESeq['posdata'],\"./Gen_data/\"+sub_dir+\"_pos.fa\",\"fasta\")\n",
    "    print sub_dir+'is processed!'\n",
    "    \n",
    "\n",
    "print 'Finished!'\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HeLa-S3\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/NHEK\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/IMR90\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/K562\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/combined\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HUVEC\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "GM12878is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HeLa-S3\n",
      "HeLa-S3is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/NHEK\n",
      "NHEKis processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/IMR90\n",
      "IMR90is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/K562\n",
      "K562is processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/combined\n",
      "combinedis processed!\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HUVEC\n",
      "HUVECis processed!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "baseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "Valid_split=0.9\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            breakbaseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "\n",
    "#method2. 读取部分并计算新键a\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            break\n",
    "    \n",
    "    #新建初始化变量\n",
    "    #method1.读取全部内容\n",
    "    #----------------------------\n",
    "    #PESeq = {}\n",
    "    #for name in excel_name:\n",
    "    #    PESeq[name] = []\n",
    "    #---------------------------\n",
    "    \n",
    "    Pos_num =0\n",
    "    Neg_num =0\n",
    "        #-------------------------------\n",
    "    PESeq={}\n",
    "    PESeq['posdata']=[]\n",
    "    PESeq['negdata']=[]\n",
    "    #PESeq['label'] =[]\n",
    "    #--------------------------------\n",
    "    \n",
    "    #读取CSV内容并结构化\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Add values of every keys to the csvdata for every row\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) <200 :\n",
    "                if     row['label']==0:\n",
    "                    print row\n",
    "                    continue\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) >40950 :\n",
    "    \n",
    "                print row\n",
    "                continue\n",
    "            if abs(int(row['promoter_start'] )-int( row['promoter_end'])) >40950 :\n",
    "                print row\n",
    "                continue                    \n",
    "            #正负样本均衡\n",
    "            if  row['label']==str(1):\n",
    "                Pos_num+=1\n",
    "            elif  row['label']==str(0) :\n",
    "                Neg_num+=1  \n",
    "            if Neg_num>Pos_num:\n",
    "                break\n",
    "            #method1.读取全部内容   \n",
    "            #---------------------------\n",
    "            #for item in csvkeys:\n",
    "            #    csvdata[item].append(row[item])\n",
    "            #------------------------------\n",
    "            #method2. 读取部分并计算新键\n",
    "            #-------------------------------\n",
    "            pro_index = row['promoter_chrom']+ ':' +row['promoter_start']+ '-'+ row['promoter_end']\n",
    "            ehr_index = row['enhancer_chrom'] +':'+ row['enhancer_start'] +'-'+row['enhancer_end']\n",
    "            pro_seq =  genome[row['promoter_chrom']][int(row['promoter_start']) :int(row['promoter_end'])] .upper()   \n",
    "            pro_seq = str(pro_seq)\n",
    "            ehr_seq =  genome[row['enhancer_chrom'] ][int(row['enhancer_start']) : int(row['enhancer_end'])].upper()    \n",
    "            ehr_seq = str(ehr_seq)\n",
    "            \n",
    "            #record = SeqRecord(Seq(pro_seq+ehr_seq),id = pro_index, description=\"\")\n",
    "            #if row['label']==str(0):\n",
    "             #   PESeq['negdata'].append(record )\n",
    "            #if row['label']== str(1):\n",
    "            #    PESeq['posdata'].append(record)\n",
    "                \n",
    "                \n",
    "            if row['label']==str(0):\n",
    "                PESeq['negdata'].append('>'+pro_index +'\\n' ) #+'-' +ehr_index\n",
    "                PESeq['negdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            if row['label']== str(1):\n",
    "                PESeq['posdata'].append('>'+pro_index +'\\n' )#+'-' +ehr_index\n",
    "                PESeq['posdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            #PESeq['label'].append(row['label'])\n",
    "            #print  [ pro_index '  -  ' ehr_index ]\n",
    "            #print [pro_seq ehr_seq]\n",
    "            #--------------------------------\n",
    "    num = len(PESeq['posdata'])//2\n",
    "    train_index =int(num*Valid_split)*2\n",
    "    with open('./Gen_data/'+sub_dir+'_pos_train.fa','w') as f:\n",
    "        f.writelines(PESeq['posdata'][:train_index])\n",
    "    with open('./Gen_data/'+sub_dir+'_pos_valid.fa','w') as f:\n",
    "        f.writelines(PESeq['posdata'][(train_index):])\n",
    "        \n",
    "    with  open('./Gen_data/'+sub_dir+'_neg_train.fa','w') as f:\n",
    "        f.writelines(PESeq['negdata'][:train_index])\n",
    "    with  open('./Gen_data/'+sub_dir+'_neg_valid.fa','w') as f:\n",
    "        f.writelines(PESeq['negdata'][(train_index):])\n",
    "    #SeqIO.write(PESeq['negdata'], \"./Gen_data/\"+sub_dir+\"_neg.fa\",\"fasta\")\n",
    "    #SeqIO.write(PESeq['posdata'],\"./Gen_data/\"+sub_dir+\"_pos.fa\",\"fasta\")\n",
    "    print sub_dir+'is processed!'\n",
    "    \n",
    "\n",
    "print 'Finished!'\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HeLa-S3\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/NHEK\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/IMR90\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/K562\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/combined\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/HUVEC\n",
      "/home/zengwanwen/enhancer/targetfinder/paper/targetfinder/GM12878\n",
      "chr1:9747084-9749721 chr1:9685722-9686400\n",
      "chr1 9747084 9749721\n",
      "chr1 9685722 9686400\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "baseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "Valid_split=0.9\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            breakbaseroot = '/home/zengwanwen/enhancer/targetfinder/paper/targetfinder'\n",
    "excel_name =[]\n",
    "\n",
    "#method2. 读取部分并计算新键\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            break\n",
    "    \n",
    "    #新建初始化变量\n",
    "    #method1.读取全部内容\n",
    "    #----------------------------\n",
    "    #PESeq = {}\n",
    "    #for name in excel_name:\n",
    "    #    PESeq[name] = []\n",
    "    #---------------------------\n",
    "    \n",
    "    Pos_num =0\n",
    "    Neg_num =0\n",
    "        #-------------------------------\n",
    "    PESeq={}\n",
    "    PESeq['posdata']=[]\n",
    "    PESeq['negdata']=[]\n",
    "    PESeq['bin']=[]\n",
    "    #PESeq['label'] =[]\n",
    "    #--------------------------------\n",
    "    negdata={}\n",
    "    #读取CSV内容并结构化\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Add values of every keys to the csvdata for every row\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) <200 :\n",
    "                if     row['label']==0:\n",
    "                    print row\n",
    "                    continue\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) >40950 :\n",
    "    \n",
    "                print row\n",
    "                continue\n",
    "            if abs(int(row['promoter_start'] )-int( row['promoter_end'])) >40950 :\n",
    "                print row\n",
    "                continue                    \n",
    "\n",
    "            #method1.读取全部内容   \n",
    "            #---------------------------\n",
    "            #for item in csvkeys:\n",
    "            #    csvdata[item].append(row[item])\n",
    "            #------------------------------\n",
    "            #method2. 读取部分并计算新键\n",
    "            #-------------------------------\n",
    "            pro_index = row['promoter_chrom']+ ':' +row['promoter_start']+ '-'+ row['promoter_end']\n",
    "            ehr_index = row['enhancer_chrom'] +':'+ row['enhancer_start'] +'-'+row['enhancer_end']\n",
    "            pro_seq =  genome[row['promoter_chrom']][int(row['promoter_start']) :int(row['promoter_end'])] .upper()   \n",
    "            pro_seq = str(pro_seq)\n",
    "            ehr_seq =  genome[row['enhancer_chrom'] ][int(row['enhancer_start']) : int(row['enhancer_end'])].upper()    \n",
    "            ehr_seq = str(ehr_seq)\n",
    "            print pro_index,ehr_index\n",
    "            print row['promoter_chrom'],row['promoter_start'],row['promoter_end']\n",
    "            print row['enhancer_chrom'],row['enhancer_start'],row['enhancer_end']\n",
    "            break\n",
    "            #record = SeqRecord(Seq(pro_seq+ehr_seq),id = pro_index, description=\"\")\n",
    "            #if row['label']==str(0):\n",
    "             #   PESeq['negdata'].append(record )\n",
    "            #if row['label']== str(1):\n",
    "            #    PESeq['posdata'].append(record)\n",
    "                \n",
    "                \n",
    "            if row['label']==str(0):\n",
    "                if row['bin'] not in negdata.keys():\n",
    "                    negdata[row['bin']]=[]\n",
    "                negdata[row['bin']].append('>'+pro_index +'\\n' )\n",
    "                #negdata[row['bin']].append(pro_seq +ehr_seq+'\\n')\n",
    "                #PESeq['negdata'].append('>'+pro_index +'\\n' ) #+'-' +ehr_index\n",
    "                #PESeq['negdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "                #PESeq['bin'].append(row['bin'])\n",
    "            if row['label']== str(1):\n",
    "                PESeq['posdata'].append('>'+pro_index +'\\n' )#+'-' +ehr_index\n",
    "                PESeq['posdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            \n",
    "            #PESeq['label'].append(row['label'])\n",
    "            #print  [ pro_index '  -  ' ehr_index ]\n",
    "            #print [pro_seq ehr_seq]\n",
    "            #--------------------------------\n",
    "        break    \n",
    "        pos_num = len(PESeq['posdata'])/2\n",
    "\n",
    "        bin_category = len(negdata.keys())\n",
    "\n",
    "        each_category_num=int(pos_num//bin_category) \n",
    "\n",
    "        real_neg_data =[]\n",
    "        \n",
    "        for category in range(bin_category):\n",
    "            real_neg_data = np.append(real_neg_data, negdata[ negdata.keys()[category] ][: 2*each_category_num ])\n",
    "            \n",
    "    \n",
    "        \n",
    "    num = len(real_neg_data)/2\n",
    "    if not isinstance(num,int):\n",
    "        print \"WRONG!!!!\"\n",
    "    train_index =int(num*Valid_split)*2       \n",
    "    with  open('./Gen_data/'+sub_dir+'_neg_train.fa','w') as f:\n",
    "        f.writelines(real_neg_data[:train_index])\n",
    "    with  open('./Gen_data/'+sub_dir+'_neg_valid.fa','w') as f:\n",
    "        f.writelines(real_neg_data[(train_index):])\n",
    "    #SeqIO.write(PESeq['negdata'], \"./Gen_data/\"+sub_dir+\"_neg.fa\",\"fasta\")\n",
    "    #SeqIO.write(PESeq['posdata'],\"./Gen_data/\"+sub_dir+\"_pos.fa\",\"fasta\")\n",
    "    print sub_dir+'is processed!'    \n",
    "\n",
    "print 'Finished!'\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model4  \n",
    "随机取负样本\n",
    "不拆分测试集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/K562\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/combined\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/HUVEC\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/GM12878\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/HeLa-S3\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/IMR90\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/NHEK\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/K562\n",
      "K562is processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/combined\n",
      "combinedis processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/HUVEC\n",
      "HUVECis processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/GM12878\n",
      "GM12878is processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/HeLa-S3\n",
      "HeLa-S3is processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/IMR90\n",
      "IMR90is processed!\n",
      "/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/NHEK\n",
      "NHEKis processed!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from pyfasta import Fasta\n",
    "genome = Fasta('/home/yinqijin/WorkSpace/DataHub/genome.fa')\n",
    "baseroot ='/home/yinqijin/WorkSpace/2.RNA_Structure_Profile/Orig_data/targetfinder/'\n",
    "excel_name =[]\n",
    "Valid_split=0.9\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            break\n",
    "excel_name =[]\n",
    "\n",
    "#method2. 读取部分并计算新键\n",
    "\n",
    "    \n",
    "    \n",
    "#读取每个pairs.csv的表头\n",
    "for sub_dir in os.listdir(baseroot):\n",
    "    cell_type_dir = os.path.join(baseroot,sub_dir)\n",
    "    print cell_type_dir\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        for line in  csv.reader(csvfile):\n",
    "            #print line\n",
    "            excel_name=line\n",
    "            break\n",
    "    \n",
    "    #新建初始化变量\n",
    "    #method1.读取全部内容\n",
    "    #----------------------------\n",
    "    #PESeq = {}\n",
    "    #for name in excel_name:\n",
    "    #    PESeq[name] = []\n",
    "    #---------------------------\n",
    "    \n",
    "    Pos_num =0\n",
    "    Neg_num =0\n",
    "        #-------------------------------\n",
    "    PESeq={}\n",
    "    PESeq['posdata']=[]\n",
    "    PESeq['negdata']=[]\n",
    "    PESeq['bin']=[]\n",
    "    #PESeq['label'] =[]\n",
    "    #--------------------------------\n",
    "    negdata={}\n",
    "    #读取CSV内容并结构化\n",
    "    with open(cell_type_dir+'/output-epw/pairs.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Add values of every keys to the csvdata for every row\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) <200 :\n",
    "                if     row['label']==0:\n",
    "                    print row\n",
    "                    continue\n",
    "            if abs(int(row['enhancer_start'] )-int( row['enhancer_end'])) >40950 :\n",
    "    \n",
    "                print row\n",
    "                continue\n",
    "            if abs(int(row['promoter_start'] )-int( row['promoter_end'])) >40950 :\n",
    "                print row\n",
    "                continue                    \n",
    "\n",
    "            #method1.读取全部内容   \n",
    "            #---------------------------\n",
    "            #for item in csvkeys:\n",
    "            #    csvdata[item].append(row[item])\n",
    "            #------------------------------\n",
    "            #method2. 读取部分并计算新键\n",
    "            #-------------------------------\n",
    "            pro_index = row['promoter_chrom']+ ':' +row['promoter_start']+ '-'+ row['promoter_end']\n",
    "            ehr_index = row['enhancer_chrom'] +':'+ row['enhancer_start'] +'-'+row['enhancer_end']\n",
    "            pro_seq =  genome[row['promoter_chrom']][int(row['promoter_start']) :int(row['promoter_end'])] .upper()   \n",
    "            pro_seq = str(pro_seq)\n",
    "            ehr_seq =  genome[row['enhancer_chrom'] ][int(row['enhancer_start']) : int(row['enhancer_end'])].upper()    \n",
    "            ehr_seq = str(ehr_seq)\n",
    "          \n",
    "              \n",
    "            if row['label']==str(0):\n",
    "                if row['bin'] not in negdata.keys():\n",
    "                    negdata[row['bin']]=[]\n",
    "                negdata[row['bin']].append('>'+pro_index+ehr_index+'_sample_0'+'\\n' )\n",
    "                negdata[row['bin']].append(pro_seq +ehr_seq+'\\n')\n",
    "                \n",
    "            if row['label']== str(1):\n",
    "                PESeq['posdata'].append('>'+pro_index +ehr_index+'_sample_1'+'\\n' )#+'-' +ehr_index\n",
    "                PESeq['posdata'].append(pro_seq +ehr_seq+'\\n')\n",
    "            \n",
    "            #--------------------------------\n",
    "     \n",
    "        pos_num = len(PESeq['posdata'])/2\n",
    "        bin_category = len(negdata.keys())\n",
    "        each_category_num=int(pos_num//bin_category) \n",
    "        real_neg_data =[]\n",
    "        for category in range(bin_category):\n",
    "            real_neg_data = np.append(real_neg_data, negdata[ negdata.keys()[category] ][: 2*each_category_num ])\n",
    "            \n",
    "    \n",
    "    with open('./Gen_data/'+sub_dir+'_pos_all.fa','w') as f:\n",
    "        f.writelines(PESeq['posdata'])\n",
    "    with  open('./Gen_data/'+sub_dir+'_neg_all.fa','w') as f:\n",
    "        f.writelines(real_neg_data)        \n",
    "        \n",
    "    print sub_dir+'is processed!'    \n",
    "\n",
    "print 'Finished!'\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
